{
  "hash": "3c242711e1cc871c601ddd1cd82473f2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Daily Notes: 2025-11-16\"\ndate: 2025-11-16\ncategories: [daily]\n---\n\n\nML Notes\n- \nImplementing the perceptron as a simple ML classification algorithm without scikit-learn\n\n- **Mc-Culloch-Pitts (MCP) neuron model**: The biological neuron as a simple logic gate with multiple input signals arriving at the dendrites and a binary output.\n- **Perceptron learning rule**: Frank Rosenblatt built upon this MCP neuron model by proposing an algorithm that would *learn* a weight vector $w$ that would be multiplied with the input features $x$ to make a decision about whether the neuron fires or not: i.e., a binary output.\n- This is helpful because it can predict with the classification problem: does a new data point belong to one class or another?\n\n\nFormally, a decision function $f(z)$ where, given a defined threshold $\\theta$:\n\n$z = w_1x_1 + w_2x_2 + ... + w_nx_n = w^Tx$\n\n::: {.callout-note}\n $w$ and $z$ are both column vectors, which is why we take the **transpose** $w^T$ to get the **dot product** of the $(n \\times 1)$ column vectors. $(1 \\times n) * (n \\times 1) = 1 \\times 1$\n:::\n\n$f(z) = \\begin{cases} 1, & z \\ge \\theta \\\\ 0, & z < \\theta \\end{cases}$\n\nIf we introduce a **bias unit** $b = -\\theta$ for ease of implementation, then:\n\n$z = w^Tx$ or $z = w_1x_1 + w_2x_2 + ... + w_nx_n + b = w^Tx + b$\n\n$y = f(z) = \\begin{cases} 1, & z \\ge 0 \\\\ 0, & z < 0 \\end{cases}$\n\nThe **perceptron learning rule** can be summarized as follows:\n\n1. Initialize the weights and bias unit to 0\n2. For each training example $x^{(i)}$, compute the output value $\\hat{y}^{(i)}$ which is the **predicted class label** of the $i$th training example, predicted by the **threshold function** $f(z)$\n3. Compare the **predicted class label** of the $i$th training example $\\hat{y}^{(i)}$ to the **true class label** of the $i$th training example $y^{(i)}$\n4. Update the weights $w$ and bias unit $b$ simultaneously\n\nFormally,\n\n$\\forall w_j \\in w, w_j := w_j + \\Delta w_j$\n\n$\\Delta w_j = \\eta(y^{(i)} - \\hat{y}^{(i)})* x^{(i)}$\n\n$b := b + \\Delta b$\n\n$\\Delta b = \\eta(y^{(i)} - \\hat{y}^{(i)})$\n\n\n::: {.callout-note}\n$:=$ is \"defined as\"\n\n$\\eta$ is the Greek letter \"eta\" and is often used for the **learning rate** in ML, typically defined as a constant between 0 & 1\n:::\n\nSome observations:\n\n- Each weight $w_j$ corresponds to a feature $x_j$. The bias unit $b$ does not.\n- Each weight update $\\Delta w_j$ is proportional to the value of $x^{(i)}_j$. The bias unit update is not. \n    - Compare $x^{(i)}_j = 10$ to $x^{(i)}_j = 1$ in the example where it is incorrectly classified as class $0$ when the true class label is $1$. Assume $\\eta = 1$. \n    - $\\Delta w_j = (1 - 0) * 10 = 10$\n    - $\\Delta w_j = (1 - 0) * 1 = 1$. \n    - The first example will push the decision boundary by a factor of $10$\n- The bias unit $b$ is part of the linear combination (the score that the perceptron computes), not the activation (the **step function**). So, $y = f(z)$ is correct, not $y = f(z) + b$. The bias shifts the **decision boundary**. \n- You can see from the formal definition that the bias unit and weights remain unchanged when the perceptron predicts the class label correctly. *The perceptron only updates when it makes a mistake in classification.*\n- If the data is **linearly separable**, the perceptron is guaranteed to find a **separating hyperplane** within a finite amount of updates. If not **linearly separable**, it will update forever - you need to maximum number of **epochs** in this situation.\n\n::: {.callout-note}\nA **step function** (in the context of perceptrons) is an activation function that outputs only two possible values. It decides yes/no based on whether the input crosses a threshold.\n\nAn **activation function** is applied to a neuron to determine whether it should \"fire\" or stay inactive.\n\nAn **epoch** is a pass over the training dataset.\n:::\n\nImplementation in Python\n\n- If you define the perceptron interface as a Python class, you can initialize new `Perceptron` objects that can learn from data using a `fit` method and make predictions using a `predict` method.\n\n::: {.callout-note}\nAn underscore _ is appended to attributes that are not created upon initialization of object, e.g., `self.w_` \n\nIn Python's OOP framework, a **class** is the blueprint, an **object** is an instance of the class, `__init__` is the **initializer** method. An **instance method** is a function defined inside a class that operates on a specific instance (object) of that class.\n\nEvery instance method must take `self` as the first parameter because you need to explicitly state which object you are applying it to, i.e., `self.something` means apply this `something` to *this* object so it **persists**. Persistence is important because after the method finishes, the object will still \"remember\" it (you're attaching it to the object itself and can run `print(object.something)` on it after the method finishes).\n:::\n\n::: {#630e8d10 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np \n\nclass Perceptron:\n    \"\"\"Perceptron classifier.\n\n    Parameters\n\n    eta: float, learning rate between 0.0 and 1.0\n    n_iter: int, epochs\n    random_state: int, random number generator for random weight initialization\n\n    Attributes\n\n    w_: 1d-array, weights after fitting\n    b_: scalar, bias unit after fitting\n    errors_: list, number of misclassifications aka updates in each epoch\n    \"\"\"\n\n    def __init__(self, eta=0.01, n_iter = 20, random_state=1):\n        self.eta = eta\n        self.n_iter = n_iter\n        self.random_state = random_state\n\n    def fit(self, X, y):\n        \"\"\"Fit training data.\n\n        Parameters \n\n        X: array, features\n        y: array, target values\n\n        Returns\n\n        self: object\n        \"\"\"\n        rgen = np.random.RandomState(self.random_state)\n        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n        self.b_ = np.float_(0.)\n        self.errors_ = []\n\n        for _ in range(self.n_iter):\n            errors = 0\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_ += update * xi\n                self.b_ += update\n                errors += int(update != 0.0)\n\n        # Will finish implementation later\n```\n:::\n\n\nPersonal Notes\n-\n- I first read about the MCP neuron model from *Why Machines Learn* by Anil Ananthaswamy and found his exposition to be helpful in understanding this chapter.\n- I implemented all of these functions with Latex. I'm slowly getting the hang of it.\n\nQuestions I still have\n- \n- N/A\n\n\nTomorrow's plan\n- \n- \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}