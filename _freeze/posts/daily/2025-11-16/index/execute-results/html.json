{
  "hash": "278dd0551aec977e5a59d2319d4ff35d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Daily Notes: 2025-11-16\"\ndate: 2025-11-16\ncategories: [daily]\n---\n\n\nML Notes\n- \nImplementing the perceptron as a simple ML classification algorithm without scikit-learn\n\n- **Mc-Culloch-Pitts (MCP) neuron model**: The biological neuron as a simple logic gate with multiple input signals arriving at the dendrites and a binary output.\n- **Perceptron learning rule**: Frank Rosenblatt built upon this MCP neuron model by proposing an algorithm that would *learn* a weight vector $w$ that would be multiplied with the input features $x$ to make a decision about whether the neuron fires or not: i.e., a binary output.\n- This is helpful because it can predict with the classification problem: does a new data point belong to one class or another?\n\n\nFormally, a decision function $f(z)$ where, given a defined threshold $\\theta$:\n\n$z = w_1x_1 + w_2x_2 + ... + w_nx_n = w^Tx$\n\n::: {.callout-note}\n $w$ and $z$ are both column vectors, which is why we take the **transpose** $w^T$ to get the **dot product** of the $(n \\times 1)$ column vectors. $(1 \\times n) * (n \\times 1) = 1 \\times 1$\n:::\n\n$f(z) = \\begin{cases} 1, & z \\ge \\theta \\\\ 0, & z < \\theta \\end{cases}$\n\nIf we introduce a **bias unit** $b = -\\theta$ for ease of implementation, then:\n\n$z = w^Tx$ or $z = w_1x_1 + w_2x_2 + ... + w_nx_n + b = w^Tx + b$\n\n$y = f(z) = \\begin{cases} 1, & z \\ge 0 \\\\ 0, & z < 0 \\end{cases}$\n\nThe **perceptron learning rule** can be summarized as follows:\n\n1. Initialize the weights and bias unit to 0\n2. For each training example $x^{(i)}$, compute the output value $\\hat{y}^{(i)}$ which is the **predicted class label** of the $i$th training example, predicted by the **threshold function** $f(z)$\n3. Compare the **predicted class label** of the $i$th training example $\\hat{y}^{(i)}$ to the **true class label** of the $i$th training example $y^{(i)}$\n4. Update the weights $w$ and bias unit $b$ simultaneously\n\nFormally,\n\n$\\forall w_j \\in w, w_j := w_j + \\Delta w_j$\n\n$\\Delta w_j = \\eta(y^{(i)} - \\hat{y}^{(i)})* x^{(i)}$\n\n$b := b + \\Delta b$\n\n$\\Delta b = \\eta(y^{(i)} - \\hat{y}^{(i)})$\n\n\n::: {.callout-note}\n$:=$ is \"defined as\"\n\n$\\eta$ is the Greek letter \"eta\" and is often used for the **learning rate** in ML, typically defined as a constant between 0 & 1\n:::\n\nSome observations:\n\n- Each weight $w_j$ corresponds to a feature $x_j$. The bias unit $b$ does not.\n- Each weight update $\\Delta w_j$ is proportional to the value of $x^{(i)}_j$. The bias unit update is not. \n    - Compare $x^{(i)}_j = 10$ to $x^{(i)}_j = 1$ in the example where it is incorrectly classified as class $0$ when the true class label is $1$. Assume $\\eta = 1$\n        - $\\Delta w_j = (1 - 0) * 10 = 10$\n        - $\\Delta w_j = (1 - 0) * 1 = 1$\n    - The first example will push the decision boundary by a factor of $10$\n- The bias unit $b$ is part of the linear combination (the score that the perceptron computes), not the activation (the **step function**). So, $y = f(z)$ is correct, not $y = f(z) + b$. The bias shifts the **decision boundary**. \n- You can see from the formal definition that the bias unit and weights remain unchanged when the perceptron predicts the class label correctly. *The perceptron only updates when it makes a mistake in classification.*\n- If the data is **linearly separable**, the perceptron is guaranteed to find a **separating hyperplane** within a finite amount of updates. If not **linearly separable**, it will update forever - you need to maximum number of **epochs** in this situation.\n\n::: {.callout-note}\nA **step function** (in the context of perceptrons) is an activation function that outputs only two possible values. It decides yes/no based on whether the input crosses a threshold.\n\nAn **activation function** is applied to a neuron to determine whether it should \"fire\" or stay inactive.\n\nAn **epoch** is a pass over the training dataset.\n:::\n\nImplementation in Python\n\n- If you define the perceptron interface as a Python class, you can initialize new `Perceptron` objects that can learn from data using a `fit` method and make predictions using a `predict` method.\n\n::: {.callout-note}\nAn underscore _ is appended to attributes that are not created upon initialization of object, e.g., `self.w_` \n\nIn Python's OOP framework, a **class** is the blueprint, an **object** is an instance of the class, `__init__` is the **initializer** method. An **instance method** is a function defined inside a class that operates on a specific instance (object) of that class.\n\nEvery instance method must take `self` as the first parameter because you need to explicitly state which object you are applying it to, i.e., `self.something` means apply this `something` to *this* object so it **persists**. Persistence is important because after the method finishes, the object will still \"remember\" it (you're attaching it to the object itself and can run `print(object.something)` on it after the method finishes).\n\nStandard practice for any model class: set hyperparameters as **instance attributes** once on creation under `__init__`, then reuse them whenever you train or retrain the model.\n:::\n\n::: {#a9c0a3b5 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np \n\nclass Perceptron:\n    \"\"\"Perceptron classifier.\n\n    Parameters\n\n    eta: float, learning rate between 0.0 and 1.0\n    n_iter: int, epochs\n    random_state: int, random number generator (RNG) for random weight initialization\n\n    Attributes\n\n    w_: 1d-array, weights after fitting\n    b_: scalar, bias unit after fitting\n    errors_: list, number of misclassifications aka updates in each epoch\n    \"\"\"\n\n    def __init__(self, eta=0.01, n_iter = 20, random_state=1):\n        self.eta = eta\n        self.n_iter = n_iter\n        self.random_state = random_state\n\n    def fit(self, X, y):\n        \"\"\"Fit training data.\n\n        Parameters \n\n        X: array, features\n        y: array, target values\n\n        Returns\n\n        self: object\n        \"\"\"\n        rgen = np.random.RandomState(self.random_state) # random number generator\n        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1]) # initializes weight vector\n        # np.random.normal samples from a Gaussian (== normal distribution) with mean (loc = 0.0, no bias towards + or -) and std (scale = 0.01, weights begin near 0)\n        # size == the number of columns in X\n        self.b_ = np.float_(0.) # initializes bias value to 0.0\n        self.errors_ = [] # logs how many samples were misclassified at each epoch\n\n        for _ in range(self.n_iter): # repeats the training pass n_iter times\n            errors = 0 # resets counter at start of each epoch\n            for xi, target in zip(X, y): # zip pairs each feature vector xi from X with the corresponding target label in y\n                update = self.eta * (target - self.predict(xi)) # update will be 0 if there was no error\n                self.w_ += update * xi\n                self.b_ += update\n                errors += int(update != 0.0) # converts Boolean (update != 0.0) to 1 if True and 0 if False\n            self.errors_.append(errors)\n        return self\n    \n    def net_input(self, X):\n        \"\"\"Calculate net input\"\"\"\n        return np.dot(X, self.w_) + self.b_ # np.dot(a, b) is the dot product of a & b\n    \n    def predict(self, X):\n        \"\"\"Return class label\"\"\"\n        return np.where(self.net_input(X) >= 0.0, 1, 0) # np.where(... >= 0.0, 1, 0) returns 1 when the net input >= 0.0, 0 otherwise\n\ndef test_perceptron_learns_and_gate():\n    # 1) Define the AND dataset\n    X = np.array([\n        [0, 0],\n        [0, 1],\n        [1, 0],\n        [1, 1],\n    ])\n    y = np.array([0, 0, 0, 1])\n\n    # 2) Create the model\n    clf = Perceptron(eta=0.1, n_iter=20, random_state=1)\n\n    # 3) Train on the dataset\n    clf.fit(X, y)\n\n    # 4) Check predictions\n    preds = clf.predict(X)\n\n    # 5) Assert predictions match the true labels\n    assert np.array_equal(preds, y)\n\nif __name__ == \"__main__\":\n    test_perceptron_learns_and_gate()\n    print(\"✅ Perceptron implementation passed.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✅ Perceptron implementation passed.\n```\n:::\n:::\n\n\nPersonal Notes\n-\n- I first read about the MCP neuron model from *Why Machines Learn* by Anil Ananthaswamy and found his exposition to be helpful in understanding this chapter.\n- I implemented all of these functions with Latex. I'm slowly getting the hang of it.\n- I learned how to use `pytest` from my command line today. Note to self: `pytest` uses a discovery pattern of a filename starting with `test_` I'm still a novice at writing tests and have been outsourcing this to AI. I understand that this is an important skill (even though LLMs are very good at this) so I should practice this...\n\nQuestions I still have\n- \n- N/A\n\n\nTomorrow's plan\n- \n- \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}