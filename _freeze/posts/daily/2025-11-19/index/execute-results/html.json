{
  "hash": "67859b104dfd7d36bc14eaf411448eca",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Daily Notes: 2025-11-19\"\ndate: 2025-11-19\ncategories: [daily]\n---\n\n\nML Notes\n- \nTraining a perceptron model on the Iris dataset\n\n- The perceptron is a binary classifier, so we will consider two flower classes from the [Iris dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data) for practical reasons. The preceptron algorithm can be extended to **multi-class classification** using the **One vs All (OvA)** method (where one class is treated as the positive class and all other classes are the negative class).\n- It's very important that the feature pair seems roughly **linearly separable** when judging whether a perceptron is a good choice.\n\n::: {#6a3ab33f .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ns = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\ndf = pd.read_csv(s, header=None, encoding='utf-8') # dataframe\n\n# print(df.tail()) # just to ensure that the data was loaded correctly\n\ny = df.iloc[0:100, 4].values # creates a np array (.values) from the species labels (4 == 5th column == species) of the first 100 rows\ny = np.where(y == 'Iris-setosa', 0, 1) # 0 if setosa, 1 if versicolor (first 100 rows only have those two species)\n\nX = df.iloc[0:100, [0, 2]].values # 100 x 2 matrix that extracts two features: sepal length (0) and petal length (2)\n\n# Plot the two iris classes in the 100 x 2 matrix to visualize how separable they are before fitting a perceptron\n# It's important that it's roughly linearly separable, which is when a perceptron would be a good choice\n\nplt.scatter(X[:50, 0], X[:50, 1], color='red', marker='o', label = 'Setosa')\nplt.scatter(X[50:100, 0], X[50:100, 1], color='blue', marker='s', label = 'Versicolor')\n\n# Note that the x-axis here would be sepal length (because it's in column 0) and y-axis would be petal length (column 1)\nplt.xlabel('Sepal length (cm)')\nplt.ylabel('Petal length (cm)')\nplt.legend(loc='upper left')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=576 height=429}\n:::\n:::\n\n\n- Seems like a linear decision boundary is possible, which means that a perceptron can classify this dataset perfectly.\n- A perceptron would be an example of a **linear classifier**\n\nPersonal Notes\n-\n- I shipped UI improvements to the [reader](https://github.com/jooonkim/reader) project. Rick Rubin was right - ship improvements to the product by focusing on what I want and need, and hope that there will be others who want the same.\n\n\nQuestions I still have\n- \n- When implementing the code, I spent a lot of time trying to figure out why the author wrote each line the way that he did. It made me wonder how much of ML is printing out tails of datasets and plotting data to visualize it as a sanity check.\n\n\nTomorrow's plan\n- \n- Finish implementing the perceptron to classify the Iris dataset.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}